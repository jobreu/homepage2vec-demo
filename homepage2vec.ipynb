{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Website classification demo with *Homepage2Vec*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is meant to demonstrate how URLs can be classified using the `homepage2vec` library for `Python`. The `homepage2vec` library is based on the [dataset](https://figshare.com/articles/dataset/Curlie_Dataset_-_Language-agnostic_Website_Embedding_and_Classification/19406693) from [curlie.org](https://curlie.org/).\n",
    "\n",
    "For further details you can consult the information provided in the [`Homepage2Vec` *GitHub* repository](https://github.com/epfl-dlab/homepage2vec)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use `Homepage2Vec` for your research, make sure to cite the associated conference paper:\n",
    "\n",
    "Lugeon, S., Piccardi, T., & West, R. (2022). Language-Agnostic Website Embedding and Classification. *arXiv preprint [arXiv:2201.03677](https://arxiv.org/pdf/2201.03677.pdf)*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: The code in the following is based on the examples provided in the [`ReadMe` file from the `homepage2vec` *GitHub* repository](https://github.com/epfl-dlab/homepage2vec/blob/master/README.md)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***IMPORTANT***: The demo notebook hosted on *MyBinder.org* is only meant for testing purposes. Hence, it should only be used for a few test URLs. If you want to use the functions/code provided here to classify a large number of URLs for your research, please copy/clone the notebook and run the notebook (or the code it contains) on your local machine or your own server."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to `homepage2vec`, we will use [`pandas`](https://pandas.pydata.org/) for data wrangling when we want to classify multiple URLs contained in one or more `.txt` files (see below)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: If you run the following code on your local machine/own server, you may have to install `homepage2vec` and `pandas` first (typically using [`pip`](https://pip.pypa.io/en/stable/) or [`conda`](https://docs.conda.io/projects/conda/en/latest/commands/install.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from homepage2vec.model import WebsiteClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to enable detailed logging for debugging purposes and to make the functions more verbose (so that they provide detailed progress information). Please note that this might cause issues in the `Jupyter` Notebook due to size limits for the cell output (you can deal with this by using the cell magic command [`%%capture`](https://ipython.readthedocs.io/en/stable/interactive/magics.html#cellmagic-capture) or adding a ; at the end of the line producing the extended output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import logging\n",
    "#logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the `WebsiteClassifier` from `homepage2vec` as the model we want to use for classifying the URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WebsiteClassifier()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify a single URL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for classifying a single URL and printing the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_website(model, url):\n",
    "    website = model.fetch_website(url)\n",
    "    scores, embeddings = model.predict(website)\n",
    "    print(url, \"class probabilities:\", scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the URL that you want to classify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"wikipedia.org\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `classify_website()` function to classify the specified URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_website(model, url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify multiple URLs contained in one or more `.txt` files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two functions: One for looping through the `.txt` file(s) to create a list of URLs and another one for classifying the URLs contained in the list."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the function for reading the URLs from the `.txt` file(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_urls(directory):\n",
    "    # create an empty list to store the URLs\n",
    "    urls = []\n",
    "\n",
    "    # loop through all the files in the directory\n",
    "    for file_name in os.listdir(directory):\n",
    "        # check if the file is a .txt file\n",
    "        if file_name.endswith('.txt'):\n",
    "            # open the file and read the contents line by line\n",
    "            with open(os.path.join(directory, file_name)) as file:\n",
    "                for line in file:\n",
    "                    # add each line to the urls list\n",
    "                    urls.append(line.strip())\n",
    "    return urls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the function for classifying the URLs from the list we created before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_websites(urls, model):\n",
    "    # create an empty list to store the classifications\n",
    "    classifications = []\n",
    "\n",
    "    # loop through all the URLs\n",
    "    for url in urls:\n",
    "        # classify the URL\n",
    "        website = model.fetch_website(url)\n",
    "        classification = model.predict(website)\n",
    "        classifications.append(classification[0])\n",
    "\n",
    "    return classifications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the functions, we first need to specify the directory containing the `.txt` file(s).\n",
    "\n",
    "*Note*: The *GitHub* repository containing this `Jupyter` Notebook contains a folder named `urls` with two exemplary `.txt` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./urls\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can create the URL list based on the content of the `.txt` file(s) in the specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = read_urls(directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB**: Depending on the number of URLs, applying this function may take some time. If you want information about the progress, you can enable logging (see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = classify_websites(urls, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After classifying the URLs, we can combine the URLs and the classification results for each of the categories into a `pandas` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the classifications into a pandas DataFrame\n",
    "classifications_df = pd.DataFrame(classifications)\n",
    "# create a new DataFrame with the urls as a column\n",
    "urls_df = pd.DataFrame({'website': urls})# concatenate the urls_df DataFrame with classifications_df\n",
    "classifications_df = pd.concat([urls_df, classifications_df], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further analysis, we can export the dataframe we have created to a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_df.to_csv(\"./classifications.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
